{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the image: \n",
    "Convert the image into a format that can be fed into the CNN. This usually involves resizing the image to a fixed size, normalizing the pixel values, and possibly converting the image to grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get the list of all files and directories in the chapters directory\n",
    "all_files_and_dirs = os.listdir('chapters')\n",
    "\n",
    "# Filter out the list for directories only\n",
    "chapter_dirs = [dir for dir in all_files_and_dirs if os.path.isdir(os.path.join('chapters', dir))]\n",
    "\n",
    "# The number of chapters is just the length of the list\n",
    "num_chapters = len(chapter_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "for i in range(1, num_chapters+1):\n",
    "    # Get the list of all files and directories in the chapter_1 directory\n",
    "    image_files = os.listdir(f'chapters/chapter_{i}')\n",
    "\n",
    "    # Filter out the list for files ending with .jepg (assuming all images are in .jepg format)\n",
    "    image_files = [file for file in image_files if file.endswith('.jpeg')]\n",
    "\n",
    "    # The number of images is just the length of the list\n",
    "    num_images = len(image_files)\n",
    "\n",
    "    for j in range(1, num_images):\n",
    "        # Load the image\n",
    "        image = Image.open(f'chapters/chapter_{i}/image_{j}.jpeg')\n",
    "\n",
    "        # Resize the image\n",
    "        image = image.resize((200, 200))  # Resize to 200x200 pixels\n",
    "\n",
    "        # Convert the image to grayscale\n",
    "        image = image.convert('L')\n",
    "\n",
    "        # Normalize the pixel values\n",
    "        image = np.array(image) / 255.0\n",
    "\n",
    "        # Convert the numpy array back to PIL Image object\n",
    "        image = Image.fromarray((image * 255).astype(np.uint8))\n",
    "\n",
    "        # Create the directory if it doesn't exist\n",
    "        os.makedirs(f'chapters_PP/chapter_{i}', exist_ok=True)\n",
    "\n",
    "        # Save the image\n",
    "        image.save(f'chapters_PP/chapter_{i}/image_{j}.jpeg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the CNN: \n",
    "\n",
    "The CNN will likely consist of several convolutional layers, followed by some fully connected layers. The convolutional layers are responsible for detecting local features such as edges, while the fully connected layers combine these local features to make a final decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layers\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(200, 200, 1)))  # Input shape: 200x200 pixels, 1 channel (grayscale)\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the tensor output by the convolutional layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add fully connected layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer: 1 node for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the CNN: \n",
    "\n",
    "Feed the preprocessed image into the CNN and use backpropagation to adjust the weights of the network. The goal is to minimize the difference between the network's output and the desired output.\n",
    "\n",
    "UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = []\n",
    "train_labels = []\n",
    "\n",
    "for i in range(1, num_chapters+1):\n",
    "    # Get the list of all files in the preprocessed chapter directory\n",
    "    image_files = os.listdir(f'chapters_PP/chapter_{i}')\n",
    "\n",
    "    # Filter out the list for files ending with .jpeg\n",
    "    image_files = [file for file in image_files if file.endswith('.jpeg')]\n",
    "\n",
    "    for j in range(1, len(image_files)-30):\n",
    "        # Load the image\n",
    "        image = Image.open(f'chapters_PP/chapter_{i}/image_{j}.jpeg')\n",
    "\n",
    "        # Convert the image to numpy array and normalize it\n",
    "        image = np.array(image) / 255.0\n",
    "\n",
    "        # Add a new axis to make it compatible with the model's input shape\n",
    "        image = np.expand_dims(image, axis=-1)\n",
    "\n",
    "        # Append the image to train_images\n",
    "        train_images.append(image)\n",
    "\n",
    "        # Append the label to train_labels\n",
    "        train_labels.append(i)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(train_images, train_labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocess the output:\n",
    "\n",
    "The output of the CNN will be a set of feature maps, which need to be postprocessed to obtain the final image. This could involve thresholding the feature maps to detect edges, and then using a technique such as the Hough transform to detect squares.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Assume that 'output' is the output of your CNN model\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(train_images)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Thresholding\u001b[39;00m\n\u001b[0;32m      8\u001b[0m _, thresholded_output \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mthreshold(output, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m1\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mTHRESH_BINARY)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Assume that 'output' is the output of your CNN model\n",
    "output = model.predict(train_images)\n",
    "\n",
    "# Thresholding\n",
    "_, thresholded_output = cv2.threshold(output, 0.5, 1, cv2.THRESH_BINARY)\n",
    "\n",
    "# Convert to 8-bit image (needed for Hough transform)\n",
    "thresholded_output = (thresholded_output * 255).astype(np.uint8)\n",
    "\n",
    "# Hough transform to detect squares\n",
    "lines = cv2.HoughLinesP(thresholded_output, 1, np.pi/180, 100, minLineLength=100, maxLineGap=10)\n",
    "\n",
    "# Draw lines on the image\n",
    "for line in lines:\n",
    "    x1, y1, x2, y2 = line[0]\n",
    "    cv2.line(output, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow('Output', output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
